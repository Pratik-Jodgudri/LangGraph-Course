{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "45752a78",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "13884f00",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\ML\\LangGraph-Udemy-Course\\.venv\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from langchain_huggingface import HuggingFaceEmbeddings\n",
    "from langchain_community.vectorstores import Chroma\n",
    "from langchain.schema import Document\n",
    "\n",
    "embedding_function = HuggingFaceEmbeddings(model='all-MiniLM-L6-v2')\n",
    "\n",
    "docs = [\n",
    "    Document(\n",
    "        page_content=\"Bella Vista is owned by Antonio Rossi, a renowned chef with over 20 years of experience in the culinary industry. He started Bella Vista to bring authentic Italian flavors to the community.\",\n",
    "        metadata={\"source\": \"owner.txt\"},\n",
    "    ),\n",
    "    Document(\n",
    "        page_content=\"Bella Vista offers a range of dishes with prices that cater to various budgets. Appetizers start at $8, main courses range from $15 to $35, and desserts are priced between $6 and $12.\",\n",
    "        metadata={\"source\": \"dishes.txt\"},\n",
    "    ),\n",
    "    Document(\n",
    "        page_content=\"Bella Vista is open from Monday to Sunday. Weekday hours are 11:00 AM to 10:00 PM, while weekend hours are extended from 11:00 AM to 11:00 PM.\",\n",
    "        metadata={\"source\": \"restaurant_info.txt\"},\n",
    "    ),\n",
    "    Document(\n",
    "        page_content=\"Bella Vista offers a variety of menus including a lunch menu, dinner menu, and a special weekend brunch menu. The lunch menu features light Italian fare, the dinner menu offers a more extensive selection of traditional and contemporary dishes, and the brunch menu includes both classic breakfast items and Italian specialties.\",\n",
    "        metadata={\"source\": \"restaurant_info.txt\"},\n",
    "    ),\n",
    "]\n",
    "\n",
    "db = Chroma.from_documents(docs, embedding_function)\n",
    "\n",
    "retriever = db.as_retriever(search_kwargs={\"k\": 2})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "aabac935",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "\n",
    "template = \"\"\"Answer the question based on the following context and the Chathistory. Especially take the latest question into consideration:\n",
    "\n",
    "Chathistory: {history}\n",
    "\n",
    "Context: {context}\n",
    "\n",
    "Question: {question}\n",
    "\"\"\"\n",
    "prompt = ChatPromptTemplate.from_template(template)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "caeef032",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_groq import ChatGroq\n",
    "\n",
    "llm = ChatGroq(model='gemma2-9b-it')\n",
    "\n",
    "rag_chain = prompt | llm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7a9877e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import TypedDict, List\n",
    "from langchain_core.messages import BaseMessage, HumanMessage, AIMessage, SystemMessage\n",
    "from langchain.schema import Document\n",
    "from pydantic import BaseModel, Field\n",
    "from langchain.prompts import ChatPromptTemplate\n",
    "from langchain_groq import ChatGroq\n",
    "\n",
    "class AgentState(TypedDict):\n",
    "    messages: List[BaseMessage]\n",
    "    documents: List[Document]\n",
    "    on_topic: str\n",
    "    rephrased_question: str\n",
    "    proceed_to_generate: bool\n",
    "    rephrase_count: int\n",
    "    question: HumanMessage\n",
    "\n",
    "class GradeQuestion(BaseModel):\n",
    "    score: str = Field(\n",
    "        description=\"Question is about the specified topics? If yes -> 'Yes' if not -> 'No'\"\n",
    "    )\n",
    "\n",
    "def question_rewriter(state: AgentState):\n",
    "    print(f\"Entering question_rewriter with following state: {state}\")\n",
    "\n",
    "    state['documents'] = []\n",
    "    state[\"on_topic\"] = \"\"\n",
    "    state['rephrased_question'] = \"\"\n",
    "    state['proceed_to_generate'] = False\n",
    "    state['rephrase_count'] = 0\n",
    "    \n",
    "    if 'messages' not in state or state['messages'] is None:\n",
    "        state['messages'] = []\n",
    "\n",
    "    if state['question'] not in state['messages']:\n",
    "        state['messages'].append(state['question'])\n",
    "\n",
    "    if len(state['messages']) > 1:\n",
    "        conversation = state['messages'][:-1]\n",
    "        current_question = state['question'].content\n",
    "        messages = [\n",
    "            SystemMessage(\n",
    "                content=\"You are a helpful assistant that rephrases the user's question to be a standalone question optimized for retrieval.\"\n",
    "            )\n",
    "        ]\n",
    "        messages.extend(conversation)\n",
    "        messages.append(HumanMessage(content=current_question))\n",
    "        rephrase_prompt = ChatPromptTemplate.from_messages(messages)\n",
    "        llm = ChatGroq(model='gemma2-9b-it')\n",
    "        chain = rephrase_prompt | llm\n",
    "        response = chain.invoke({})\n",
    "        better_question = response.content.strip()\n",
    "        print(f\"question_rewriter: Rephrased question: {better_question}\")\n",
    "        state[\"rephrased_question\"] = better_question\n",
    "    else:\n",
    "        state[\"rephrased_question\"] = state[\"question\"].content\n",
    "    return state\n",
    "        \n",
    "def question_classifier(state: AgentState):\n",
    "    print(\"Entering question_classifier\")\n",
    "\n",
    "    system_text = \"\"\"You are a classifier. Your task is to determine if the user's question is about one of the following specific topics concerning the restaurant Bella Vista:\n",
    "\n",
    "    1. Information about the owner of Bella Vista, Antonio Rossi.\n",
    "    2. Prices of dishes at Bella Vista.\n",
    "    3. Opening hours of Bella Vista.\n",
    "\n",
    "    Based on whether the question falls into one of these categories, you will determine the appropriate value for the 'score' field in the output schema.\n",
    "    \"\"\"\n",
    "    system_message = SystemMessage(content=system_text)\n",
    "    human_message = HumanMessage(\n",
    "        content = f\"User Question: {state['rephrased_question']}\"\n",
    "    )\n",
    "    grade_prompt = ChatPromptTemplate.from_messages([system_message, human_message])\n",
    "    llm = ChatGroq(model='gemma2-9b-it')\n",
    "    structured_llm = llm.with_structured_output(GradeQuestion)\n",
    "    grader_llm = grade_prompt | structured_llm\n",
    "    result = grader_llm.invoke({})\n",
    "    state[\"on_topic\"] = result.score.strip()\n",
    "    print(f\"question_classifier: on_topic = {state['on_topic']}\")\n",
    "    return state\n",
    "\n",
    "def on_topic_router(state: AgentState):\n",
    "    print(\"Entering on_topic_router\")\n",
    "    on_topic = state.get(\"on_topic\", \"\").strip().lower()\n",
    "    if on_topic == \"yes\":\n",
    "        print(\"Routing to retrieve\")\n",
    "        return \"retrieve\"\n",
    "    else:\n",
    "        print(\"Routing to off_topic_response\")\n",
    "        return \"off_topic_response\"\n",
    "\n",
    "def retrieve(state: AgentState):\n",
    "    print(\"Entering retrieve\")\n",
    "    documents = retriever.invoke(state[\"rephrased_question\"])\n",
    "    print(f\"retrieve: Retrieved {len(documents)} documents\")\n",
    "    state[\"documents\"] = documents\n",
    "    return state\n",
    "\n",
    "class GradeDocument(BaseModel):\n",
    "    score: str = Field(\n",
    "        description=\"Document is relevant to the question? If yes -> 'Yes' if not -> 'No'\"\n",
    "    )\n",
    "\n",
    "def retrieval_grader(state: AgentState):\n",
    "    print(\"Entering retrieval_grader\")\n",
    "\n",
    "    system_message = SystemMessage(\n",
    "        content = \"\"\"You are a classifier. Your task is to determine whether a retrieved document is relevant to a user's question.\n",
    "        Based on whether the document is relevant to the user's question, you will determine the appropriate value for the 'score' field in the output schema.\n",
    "        \"\"\"\n",
    "    )\n",
    "    llm = ChatGroq(model='gemma2-9b-it')\n",
    "    structured_llm = llm.with_structured_output(GradeDocument)\n",
    "\n",
    "    relevant_docs = []\n",
    "    for doc in state['documents']:\n",
    "        human_message = HumanMessage(\n",
    "            content = f\"User Question: {state['rephrased_question']}\\n\\nRetrieved Documents:\\n{doc.page_content}\"\n",
    "        )\n",
    "        grade_prompt = ChatPromptTemplate.from_messages([system_message, human_message])\n",
    "        grader_chain = grade_prompt | structured_llm\n",
    "        result = grader_chain.invoke({})\n",
    "        print(\n",
    "            f\"Grading document: {doc.page_content[:30]}... Result: {result.score.strip()}\"\n",
    "        )\n",
    "        if result.score.strip().lower() == \"yes\":\n",
    "            relevant_docs.append(doc)\n",
    "\n",
    "    state[\"documents\"] = relevant_docs\n",
    "    state[\"proceed_to_generate\"] = len(relevant_docs) > 0\n",
    "    print(f\"retrieval_grader: proceed_to_generate = {state['proceed_to_generate']}\")\n",
    "    return state\n",
    "\n",
    "        \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3061b1f8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6a0bea2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fea6c67",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf6d9560",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d1f95af",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
